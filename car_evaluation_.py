# -*- coding: utf-8 -*-
"""Car_Evaluation.

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ICORIi_qTgSE25CZ33C_cAc0IQ9Oj7ub
"""

# Install library yang diperlukan
!pip install ucimlrepo imbalanced-learn

import pandas as pd
from google.colab import files

uploaded = files.upload()
file_path = list(uploaded.keys())[0]
df = pd.read_csv(file_path)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE

# Load dataset
df = pd.read_csv("Dataset_Obesity.csv")  # Ganti dengan path dataset Anda

# Cek dan isi missing values
df.fillna(df.median(numeric_only=True), inplace=True)

# Encode target variable
df["NObeyesdad"] = df["NObeyesdad"].astype('category').cat.codes

# Definisikan fitur dan target
X = df.drop(columns=["NObeyesdad"])
y = df["NObeyesdad"]

# Cek apakah ada kelas yang hilang dalam target
print("Distribusi kelas sebelum split:")
print(y.value_counts())

# Split dataset dengan stratifikasi
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Gunakan SMOTE untuk menangani ketidakseimbangan data
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

# Cek distribusi kelas setelah SMOTE
print("\nDistribusi kelas setelah SMOTE:")
print(y_train.value_counts())

# Definisikan fitur kategori dan numerik
categorical_features = ["Gender", "family_history_with_overweight", "FAVC", "CAEC", "SMOKE", "SCC", "CALC", "MTRANS"]
numerical_features = ["Age", "Height", "Weight", "FCVC", "NCP", "CH2O", "FAF", "TUE"]

# Preprocessing pipeline
preprocessor = ColumnTransformer([
    ("cat", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1), categorical_features),
    ("num", StandardScaler(), numerical_features)
])

# Definisikan model
models = {
    "Decision Tree": DecisionTreeClassifier(),
    "NaÃ¯ve Bayes": GaussianNB(),
    "KNN": KNeighborsClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Support Vector Machine": LinearSVC(random_state=0, tol=1e-5),
    "Artificial Neural Network": MLPClassifier(solver="adam", max_iter=2000, alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1),
}

# Definisikan hyperparameter untuk GridSearchCV
param_grids = {
    "Decision Tree": {"classifier__max_depth": [3, 5, 10, None], "classifier__criterion": ["gini", "entropy"]},
    "KNN": {"classifier__n_neighbors": [3, 5, 7, 9], "classifier__weights": ["uniform", "distance"]},
    "Logistic Regression": {"classifier__C": [0.1, 1, 10, 100], "classifier__solver": ["lbfgs", "liblinear"]},
}

# Perbaiki Logistic Regression
models["Logistic Regression"] = LogisticRegression(max_iter=5000, solver="saga", C=1)

# Perbaiki Linear SVC
models["Support Vector Machine"] = LinearSVC(random_state=0, tol=1e-5, max_iter=5000)

# Tambahkan grid search untuk SVM (jika ingin optimasi lebih lanjut)
param_grids["Support Vector Machine"] = {
    "classifier__C": [0.1, 1, 10],
    "classifier__loss": ["hinge", "squared_hinge"]
}

# Training dan evaluasi model
for model_name, model in models.items():
    print(f"\nðŸ”¹ Training model: {model_name}...")
    pipeline = Pipeline([("preprocessing", preprocessor), ("classifier", model)])

    param_grid = param_grids.get(model_name, {})

    if param_grid:
        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring="accuracy", n_jobs=-1)
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        best_params = grid_search.best_params_
    else:
        best_model = pipeline.fit(X_train, y_train)
        best_params = "Default parameters"

    y_pred = best_model.predict(X_test)

    # Simpan hasil evaluasi
    results[model_name] = {
        "best_params": grid_search.best_params_,
        "accuracy": accuracy_score(y_test, y_pred),
        "classification_report": classification_report(y_test, y_pred)
    }

    # Print hasil
    print(f"âœ… Best Params: {grid_search.best_params_}")
    print(f"âœ… Accuracy: {results[model_name]['accuracy']:.2f}")
    print(f"âœ… Classification Report:\n{results[model_name]['classification_report']}")